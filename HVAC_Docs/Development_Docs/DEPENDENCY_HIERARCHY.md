# HVAC_ideas Dependency Hierarchy

This document provides a comprehensive view of all dependencies in the HVAC_ideas project, organized by category and showing the complete dependency tree.

**Last Updated:** 2026-01-15

---

## ğŸ“Š Dependency Tree Overview

```
HVAC_ideas Project
â”œâ”€â”€ System Dependencies (OS-level)
â”œâ”€â”€ Runtime Dependencies (Docker, Ollama, Python)
â”œâ”€â”€ Python Package Dependencies (pip)
â”œâ”€â”€ Script Dependencies (Shell â†’ Python)
â”œâ”€â”€ Internal Module Dependencies (Python â†’ Python)
â””â”€â”€ Documentation Dependencies
```

---

## ğŸ–¥ï¸ System Dependencies

### Required Operating Systems
- **macOS** - Primary development and testing platform
  - Required for: `resolve_system_issues.sh` (uses macOS `log show` command)
  - Version: macOS 11.0+ recommended

### Optional
- **Linux** - Compatible for most features except macOS-specific log resolution
- **Windows** - Compatible via WSL (Windows Subsystem for Linux)

---

## ğŸ³ Runtime Dependencies

### 1. Python Environment

```
Python 3.8+
â”œâ”€â”€ Virtual Environment (venv) - OPTIONAL
â”‚   â””â”€â”€ Isolates project dependencies
â””â”€â”€ System Python 3 - FALLBACK
    â””â”€â”€ Used when venv not available
```

**Installation:**
```bash
# Create virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
```

### 2. Docker Ecosystem (for Virtual HVAC Technician only)

```
Docker Desktop
â””â”€â”€ CrewAI Container
    â”œâ”€â”€ Python Runtime
    â”œâ”€â”€ CrewAI Framework
    â””â”€â”€ Network Connection to Ollama
```

**Required for:** `hvac-technician/` subproject only
**Not required for:** Oil tank diagnostic tools

### 3. Ollama (for Virtual HVAC Technician only)

```
Ollama Runtime
â””â”€â”€ llama3.2:3b Model
    â””â”€â”€ 3 billion parameter local language model
```

**Installation:**
```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.2:3b
```

**Required for:** `hvac-technician/` subproject only
**Cost:** FREE (runs locally)

---

## ğŸ“¦ Python Package Dependencies

### From requirements.txt

```
requirements.txt
â”œâ”€â”€ feedparser              # RSS feed parsing
â”œâ”€â”€ google-generativeai     # Google Gemini AI (optional)
â”œâ”€â”€ python-dotenv          # Environment variable loading
â”œâ”€â”€ beautifulsoup4         # HTML parsing
â”œâ”€â”€ requests               # HTTP requests
â”œâ”€â”€ scikit-learn           # Machine learning (clustering)
â”œâ”€â”€ numpy                  # Numerical computing
â””â”€â”€ python-dateutil        # Date parsing utilities
```

### Additional Dependencies (Not in requirements.txt)

```
Additional Python Packages
â”œâ”€â”€ anthropic              # Claude API for AI diagnostics
â”‚   â””â”€â”€ Used by: ai_tank1_diagnostic.py, ai_tank2_diagnostic.py
â”‚
â””â”€â”€ reportlab              # PDF generation
    â””â”€â”€ Used by: generate_tank1_diagnostic_pdf.py, generate_troubleshooting_pdf.py
```

**Installation:**
```bash
# Install from requirements.txt
pip install -r requirements.txt

# Install additional dependencies
pip install anthropic reportlab
```

---

## ğŸ”§ Script â†’ Execution Dependencies

### Shell Scripts (scripts/) â†’ Python Files (execution/)

```
scripts/
â”‚
â”œâ”€â”€ run_ai_diagnostic.sh
â”‚   â”œâ”€â”€ Requires: anthropic library
â”‚   â”œâ”€â”€ Requires: .env.diagnostic with ANTHROPIC_API_KEY
â”‚   â””â”€â”€ Executes: execution/ai_tank1_diagnostic.py
â”‚
â”œâ”€â”€ run_ai_tank2_diagnostic.sh
â”‚   â”œâ”€â”€ Requires: anthropic library
â”‚   â”œâ”€â”€ Requires: .env.diagnostic with ANTHROPIC_API_KEY
â”‚   â””â”€â”€ Executes: execution/ai_tank2_diagnostic.py
â”‚
â”œâ”€â”€ run_tank1_diagnostic.sh
â”‚   â”œâ”€â”€ Requires: No external API
â”‚   â””â”€â”€ Executes: execution/tank1_diagnostic_app.py
â”‚
â”œâ”€â”€ run_tank2_diagnostic.sh
â”‚   â”œâ”€â”€ Requires: No external API
â”‚   â””â”€â”€ Executes: execution/tank2_diagnostic_app.py
â”‚
â””â”€â”€ resolve_system_issues.sh
    â”œâ”€â”€ Requires: macOS system
    â”œâ”€â”€ Requires: log show command
    â”œâ”€â”€ Executes (Phase 1): execution/parse_macos_logs.py
    â”œâ”€â”€ Executes (Phase 2): execution/agent_debate.py
    â””â”€â”€ Executes (Phase 3): execution/agent_coordinator.py
```

---

## ğŸ Python Module Dependencies

### Execution Scripts Internal Dependencies

```
execution/
â”‚
â”œâ”€â”€ ai_tank1_diagnostic.py
â”‚   â”œâ”€â”€ anthropic (external)
â”‚   â”œâ”€â”€ os, sys, json (stdlib)
â”‚   â”œâ”€â”€ dotenv (load_dotenv)
â”‚   â””â”€â”€ datetime (stdlib)
â”‚
â”œâ”€â”€ ai_tank2_diagnostic.py
â”‚   â”œâ”€â”€ anthropic (external)
â”‚   â”œâ”€â”€ os, sys, json (stdlib)
â”‚   â”œâ”€â”€ dotenv (load_dotenv)
â”‚   â””â”€â”€ datetime (stdlib)
â”‚
â”œâ”€â”€ tank1_diagnostic_app.py
â”‚   â”œâ”€â”€ sys (stdlib)
â”‚   â””â”€â”€ datetime (stdlib)
â”‚
â”œâ”€â”€ tank2_diagnostic_app.py
â”‚   â”œâ”€â”€ sys (stdlib)
â”‚   â””â”€â”€ datetime (stdlib)
â”‚
â”œâ”€â”€ parse_macos_logs.py
â”‚   â”œâ”€â”€ sys, re (stdlib)
â”‚   â”œâ”€â”€ collections.defaultdict, Counter
â”‚   â””â”€â”€ datetime
â”‚
â”œâ”€â”€ agent_debate.py
â”‚   â”œâ”€â”€ sys, json (stdlib)
â”‚   â””â”€â”€ dataclasses
â”‚
â”œâ”€â”€ agent_coordinator.py
â”‚   â”œâ”€â”€ sys, json (stdlib)
â”‚   â”œâ”€â”€ datetime
â”‚   â””â”€â”€ pathlib.Path
â”‚
â”œâ”€â”€ generate_tank1_diagnostic_pdf.py
â”‚   â”œâ”€â”€ reportlab.* (external)
â”‚   â”œâ”€â”€ datetime
â”‚   â””â”€â”€ pathlib.Path
â”‚
â”œâ”€â”€ generate_troubleshooting_pdf.py
â”‚   â”œâ”€â”€ reportlab.* (external)
â”‚   â””â”€â”€ datetime
â”‚
â”œâ”€â”€ fetch_rss.py
â”‚   â”œâ”€â”€ feedparser (external)
â”‚   â”œâ”€â”€ json
â”‚   â””â”€â”€ datetime, timedelta
â”‚
â”œâ”€â”€ clean_reddit_data.py
â”‚   â”œâ”€â”€ json
â”‚   â””â”€â”€ dateutil.parser (external)
â”‚
â”œâ”€â”€ evaluate_posts.py
â”‚   â”œâ”€â”€ google.generativeai (external)
â”‚   â”œâ”€â”€ dotenv (external)
â”‚   â”œâ”€â”€ os, json, sys, time
â”‚   â””â”€â”€ typing
â”‚
â”œâ”€â”€ cluster_stories.py
â”‚   â”œâ”€â”€ sklearn.cluster.AgglomerativeClustering (external)
â”‚   â”œâ”€â”€ numpy (external)
â”‚   â”œâ”€â”€ json, sys
â”‚   â””â”€â”€ typing
â”‚
â”œâ”€â”€ summarize_posts.py
â”‚   â”œâ”€â”€ google.generativeai (external)
â”‚   â”œâ”€â”€ dotenv (external)
â”‚   â”œâ”€â”€ os, json, sys
â”‚   â””â”€â”€ typing
â”‚
â”œâ”€â”€ evaluate_clusters.py
â”‚   â”œâ”€â”€ google.generativeai (external)
â”‚   â”œâ”€â”€ json, sys
â”‚   â””â”€â”€ typing
â”‚
â””â”€â”€ summarize_clusters.py
    â”œâ”€â”€ google.generativeai (external)
    â”œâ”€â”€ json, sys
    â””â”€â”€ typing
```

---

## ğŸŒ External API Dependencies

### Required API Keys

```
External APIs
â”‚
â”œâ”€â”€ Anthropic Claude API
â”‚   â”œâ”€â”€ Required for: AI-powered diagnostics
â”‚   â”œâ”€â”€ Configuration: .env.diagnostic
â”‚   â”œâ”€â”€ Environment Variable: ANTHROPIC_API_KEY
â”‚   â”œâ”€â”€ Cost: ~$0.01-0.05 per diagnostic session
â”‚   â””â”€â”€ Used by:
â”‚       â”œâ”€â”€ ai_tank1_diagnostic.py
â”‚       â””â”€â”€ ai_tank2_diagnostic.py
â”‚
â””â”€â”€ Google Gemini API (Optional)
    â”œâ”€â”€ Required for: Reddit/RSS processing features
    â”œâ”€â”€ Configuration: .env or python-dotenv
    â”œâ”€â”€ Environment Variable: GOOGLE_API_KEY
    â”œâ”€â”€ Cost: Varies by usage
    â””â”€â”€ Used by:
        â”œâ”€â”€ evaluate_posts.py
        â”œâ”€â”€ summarize_posts.py
        â”œâ”€â”€ evaluate_clusters.py
        â””â”€â”€ summarize_clusters.py
```

---

## ğŸ“ Configuration File Dependencies

### Environment Files

```
Configuration Files
â”‚
â”œâ”€â”€ .env.diagnostic
â”‚   â”œâ”€â”€ Format: KEY=value
â”‚   â”œâ”€â”€ Required Keys:
â”‚   â”‚   â””â”€â”€ ANTHROPIC_API_KEY
â”‚   â”œâ”€â”€ Optional Keys:
â”‚   â”‚   â””â”€â”€ MODEL (Claude model selection)
â”‚   â””â”€â”€ Used by:
â”‚       â”œâ”€â”€ ai_tank1_diagnostic.py
â”‚       â””â”€â”€ ai_tank2_diagnostic.py
â”‚
â”œâ”€â”€ .env.diagnostic.example
â”‚   â””â”€â”€ Template for .env.diagnostic
â”‚
â”œâ”€â”€ env.example
â”‚   â””â”€â”€ Generic environment template
â”‚
â””â”€â”€ requirements.txt
    â””â”€â”€ Python package dependencies
```

---

## ğŸ“š Documentation Dependencies

### Document Cross-References

```
Documentation Hierarchy
â”‚
â”œâ”€â”€ README.md (Root)
â”‚   â”œâ”€â”€ â†’ HVAC_Docs/README.md
â”‚   â”œâ”€â”€ â†’ CLAUDE.md
â”‚   â”œâ”€â”€ â†’ CHANGELOG.md
â”‚   â””â”€â”€ â†’ HVAC_Docs/Technical_Guides/*.md
â”‚
â”œâ”€â”€ CLAUDE.md, AGENTS.md, GEMINI.md
â”‚   â”œâ”€â”€ â†’ directives/ (Layer 1)
â”‚   â”œâ”€â”€ â†’ execution/ (Layer 3)
â”‚   â””â”€â”€ â†’ HVAC_Docs/
â”‚
â”œâ”€â”€ HVAC_Docs/README.md
â”‚   â”œâ”€â”€ â†’ Technical_Guides/*.md
â”‚   â”œâ”€â”€ â†’ Procedures/*.md
â”‚   â”œâ”€â”€ â†’ Development_Docs/*.md
â”‚   â””â”€â”€ â†’ Prompts_and_Guides/*.md
â”‚
â””â”€â”€ CHANGELOG.md
    â””â”€â”€ â†’ DOCUMENTATION_TRACKING.md (this file)
```

---

## ğŸ”„ Data Flow Dependencies

### Runtime Data Flow

```
User Input
    â†“
Shell Script (scripts/)
    â†“
Python Execution Script (execution/)
    â†“
    â”œâ”€â†’ External API (Anthropic/Google) [if required]
    â”‚     â†“
    â”‚   API Response
    â”‚     â†“
    â””â”€â†’ Processing Logic
          â†“
        Output Files (.tmp/)
          â†“
        User Output (Terminal/File)
```

### Example: AI Tank Diagnostic Flow

```
User runs: ./scripts/run_ai_diagnostic.sh
    â†“
run_ai_diagnostic.sh
    â”œâ”€â†’ Checks: .env.diagnostic exists
    â”œâ”€â†’ Loads: venv or system Python
    â”œâ”€â†’ Verifies: anthropic library installed
    â””â”€â†’ Executes: execution/ai_tank1_diagnostic.py
              â†“
         ai_tank1_diagnostic.py
              â”œâ”€â†’ Loads: .env.diagnostic (ANTHROPIC_API_KEY)
              â”œâ”€â†’ Imports: anthropic library
              â”œâ”€â†’ Creates: Claude API client
              â”œâ”€â†’ Prompts: User for diagnostic information
              â”œâ”€â†’ Sends: User input to Claude API
              â”œâ”€â†’ Receives: AI diagnostic response
              â”œâ”€â†’ Saves: Conversation to .tmp/Tank1_AI_Conversation_*.txt
              â””â”€â†’ Outputs: Diagnostic results to terminal
```

---

## ğŸ¯ Dependency Groups by Feature

### Feature 1: AI Tank Diagnostics (Claude API - PAID)

**Dependencies:**
```
System:
  - Python 3.8+
  - Internet connection

Python Packages:
  - anthropic
  - python-dotenv

Configuration:
  - .env.diagnostic with ANTHROPIC_API_KEY

Scripts:
  - scripts/run_ai_diagnostic.sh
  - scripts/run_ai_tank2_diagnostic.sh

Execution:
  - execution/ai_tank1_diagnostic.py
  - execution/ai_tank2_diagnostic.py
```

### Feature 2: Basic Tank Diagnostics (FREE)

**Dependencies:**
```
System:
  - Python 3.8+

Python Packages:
  - None (stdlib only)

Scripts:
  - scripts/run_tank1_diagnostic.sh
  - scripts/run_tank2_diagnostic.sh

Execution:
  - execution/tank1_diagnostic_app.py
  - execution/tank2_diagnostic_app.py
```

### Feature 3: Virtual HVAC Technician (FREE, LOCAL)

**Dependencies:**
```
System:
  - Docker Desktop
  - Ollama with llama3.2:3b model

Python Packages:
  - CrewAI (in Docker container)

Subproject:
  - hvac-technician/

Execution:
  - hvac-technician/hvac_expert.py
```

### Feature 4: Multi-Agent Log Resolution

**Dependencies:**
```
System:
  - macOS (for log show command)
  - Python 3.8+

Python Packages:
  - None (stdlib only)

Scripts:
  - scripts/resolve_system_issues.sh

Execution:
  - execution/parse_macos_logs.py
  - execution/agent_debate.py
  - execution/agent_coordinator.py
```

### Feature 5: Reddit/RSS Processing (Optional)

**Dependencies:**
```
System:
  - Python 3.8+
  - Internet connection

Python Packages:
  - feedparser
  - google-generativeai
  - python-dotenv
  - beautifulsoup4
  - requests
  - scikit-learn
  - numpy
  - python-dateutil

Configuration:
  - .env with GOOGLE_API_KEY

Execution:
  - execution/fetch_rss.py
  - execution/clean_reddit_data.py
  - execution/evaluate_posts.py
  - execution/cluster_stories.py
  - execution/summarize_posts.py
  - execution/evaluate_clusters.py
  - execution/summarize_clusters.py
```

### Feature 6: PDF Generation

**Dependencies:**
```
System:
  - Python 3.8+

Python Packages:
  - reportlab

Execution:
  - execution/generate_tank1_diagnostic_pdf.py
  - execution/generate_troubleshooting_pdf.py
```

---

## ğŸš€ Quick Setup Guide by Feature

### Minimal Setup (Basic Diagnostics - FREE)
```bash
# No dependencies needed!
./scripts/run_tank1_diagnostic.sh
./scripts/run_tank2_diagnostic.sh
```

### AI Diagnostics Setup (Claude API - PAID)
```bash
# Install Python dependencies
pip install anthropic python-dotenv

# Create configuration
cp .env.diagnostic.example .env.diagnostic
# Edit .env.diagnostic and add your ANTHROPIC_API_KEY

# Run
./scripts/run_ai_diagnostic.sh
```

### Virtual HVAC Technician Setup (FREE, LOCAL)
```bash
# Install Ollama
# Download from https://ollama.ai

# Pull model
ollama pull llama3.2:3b

# Start Docker container (requires docker-compose setup)
docker compose up -d

# Run
docker compose exec crewai python /app/HVAC_ideas/hvac-technician/hvac_expert.py
```

### Full Setup (All Features)
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install all dependencies
pip install -r requirements.txt
pip install anthropic reportlab

# Configure API keys
cp .env.diagnostic.example .env.diagnostic
# Edit .env.diagnostic with ANTHROPIC_API_KEY

# Install Ollama and pull model
ollama pull llama3.2:3b

# Ready to use all features!
```

---

## ğŸ“‹ Dependency Checklist

Use this checklist to verify your environment is properly configured:

### Core Dependencies
- [ ] Python 3.8+ installed
- [ ] Can run `python3 --version` successfully

### Optional: Virtual Environment
- [ ] Virtual environment created (`python3 -m venv venv`)
- [ ] Virtual environment activated (`source venv/bin/activate`)

### For AI Diagnostics (Claude API)
- [ ] `anthropic` library installed (`pip install anthropic`)
- [ ] `.env.diagnostic` file exists
- [ ] `ANTHROPIC_API_KEY` set in `.env.diagnostic`
- [ ] Internet connection available

### For Virtual HVAC Technician
- [ ] Docker Desktop installed and running
- [ ] Ollama installed and running
- [ ] `llama3.2:3b` model downloaded (`ollama pull llama3.2:3b`)
- [ ] CrewAI container built and running

### For Reddit/RSS Processing
- [ ] All packages from `requirements.txt` installed
- [ ] `.env` file with `GOOGLE_API_KEY` (if using Gemini)

### For macOS Log Resolution
- [ ] Running on macOS system
- [ ] `log show` command available

### For PDF Generation
- [ ] `reportlab` library installed (`pip install reportlab`)

---

## ğŸ” Troubleshooting Dependencies

### Common Issues

**Issue:** `ModuleNotFoundError: No module named 'anthropic'`
```bash
# Solution:
pip install anthropic
```

**Issue:** `API key not found`
```bash
# Solution:
# 1. Check .env.diagnostic exists
ls -la .env.diagnostic

# 2. Verify ANTHROPIC_API_KEY is set
cat .env.diagnostic | grep ANTHROPIC_API_KEY

# 3. Create from template if missing
cp .env.diagnostic.example .env.diagnostic
# Then edit .env.diagnostic with your API key
```

**Issue:** `Cannot connect to Ollama`
```bash
# Solution:
# 1. Check Ollama is running
ollama list

# 2. Verify model is downloaded
ollama pull llama3.2:3b

# 3. Check Docker container networking
docker ps | grep crewai
```

**Issue:** `log show: command not found`
```bash
# Solution:
# This feature requires macOS
# Use on macOS system or skip multi-agent log resolution
```

---

## ğŸ“Š Dependency Summary

| Category | Count | Type |
|----------|-------|------|
| **System Dependencies** | 3 | OS, Docker, Ollama |
| **Python Packages (requirements.txt)** | 8 | External libraries |
| **Python Packages (additional)** | 2 | anthropic, reportlab |
| **Shell Scripts** | 5 | Launcher scripts |
| **Python Execution Scripts** | 16 | Core logic |
| **External APIs** | 2 | Anthropic, Google |
| **Configuration Files** | 3 | .env files |
| **Subprojects** | 1 | hvac-technician |

---

## ğŸ”— Related Documentation

- [Project Context](PROJECT_CONTEXT.md) - Complete project overview
- [Documentation Tracking](DOCUMENTATION_TRACKING.md) - Git workflow guide
- [LLM Switching Guide](LLM_SWITCHING_GUIDE.md) - How to switch between AI models
- [README.md](../../README.md) - Main project documentation

---

**Document Maintained By:** AI + Human collaboration
**Update Frequency:** As dependencies change
**Version Control:** Tracked in git with project
